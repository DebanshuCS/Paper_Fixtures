REVIEW
Privacy and human behavior in the
age of information
Alessandro Acquisti,1* Laura Brandimarte,1 George Loewenstein2
This Review summarizes and draws connections between diverse streams of empirical
research on privacy behavior. We use three themes to connect insights from social and
behavioral sciences: people’s uncertainty about the consequences of privacyrelated
behaviors and their own p over those consequences; the contextdependence
of people’s concern, or lack thereof, about privacy; and the degree to which privacy
concerns are malleable manipulable by commercial and governmental interests.
Organizing our discussion by these themes, we offer observations concerning the role
of public policy in the protection of privacy in the information age.
I
f this is the age of information, then privacy is
the issue of our times. Activities that were
once private or shared with the few now leave
trails of data that expose our interests, traits,
beliefs,andintentions.We communicateusing
emails, texts, and social media; find partners on
dating sites; learn via online courses; seek responses to mundane and sensitive questions using
search engines; read news and books in the cloud;
navigate streets with geotracking systems; and cel
ebrate our newborns, and mourn our dead, on
social media profiles. Through these and other
activities, we reveal information both knowingly
and unwittingly to one another, to commercial
entities, and to our governments. The monitoring
of personal information is ubiquitous; its storage
is so durable as to render one’s past undeletable
 a modern digital skeleton in the closet. Accompanying the acceleration in data collection
are steady advancements in the ability to aggregate, analyze, and draw sensitive inferences
from individuals’ data .
Both firms and individuals can benefit from the
sharing of once hidden data and from the appli
cation of increasingly sophisticated analytics to
larger and more interconnected databases . So
too can society as a whole for instance, when elec
tronic medical records are combined to observe
novel drug interactions . On the other hand, the
potential for personal data to be abused for economic and social discrimination, hidden influence
andmanipulation,coercion,orcensorship is alarming. The erosion of privacy can threaten our auton
omy, not merely as consumers but as citizens .
Sharing more personal data does not necessarily
always translate into more progress, efficiency,
or equality .
Because of the seismic nature of these develop
ments, there has been considerable debate about
individuals’ ability to navigate a rapidly evolving
privacy landscape, and about what, if anything,
should be done about privacy at a policy level.
Some trust people’s ability to make selfinterested
decisions about information disclosing and with
holding. Those holding this view tend to see
regulatory protection of privacy as interfering
with the fundamentally benign trajectory of in
formation technologies and the benefits such
technologies may unlock . Others are con
cerned about the ability of individuals to manage
privacy amid increasingly complex tradeoffs. Tra
ditional tools for privacy decisionmaking such as
choice and consent, according to this perspective,
no longer provide adequate protection . In
stead of individual responsibility, regulatory inter
vention may be needed to balance the interests
of the subjects of data against the power of
commercial entities and governments holding
that data.
Are individuals up to the challenge of navigat
ing privacy in the information age? To address
this question, we review diverse streams of empir
ical privacy research from the social and behav
ioral sciences. We highlight factors that influence
decisions to protect or surrender privacy and
how, in turn, privacy protections or violations
affect people’s behavior. Information technolo
gies have progressively encroached on every as
pect of our personal and professional lives. Thus,
the problem of control over personal data has
become inextricably linked to problems of per
sonal choice, autonomy, and socioeconomic power.
Accordingly, this Review focuses on the concept
of, and literature around, informational privacy
(that is, privacy of personal data) but also touches
on other conceptions of privacy, such as ano
nymity or seclusion. Such notions all ultimately
relate to the permeable yet pivotal boundaries
between public and private .
We use three themes to organize and draw
connections between streams of privacy research
that, in many cases, have unfolded independent
ly. The first theme is people’s uncertainty about
the nature of privacy tradeoffs, and their own
p  over them. The second is the powerful
contextdependence of privacy p: The
same person can in some situations be oblivious
to, but in other situations be acutely concerned
about, issues of privacy. The third theme is the
malleability of privacy , by which we
mean that privacy  are subject to
influence by those possessing greater insight
into their determinants. Although most individuals are probably unaware of the diverse in
fluences on their concern about privacy, entities
whose interests depend on information revelation by others are not. The manipulation of subtle
factors that activate or suppress privacy concern
can be seen in myriad realms such as the choice
of sharing defaults on social networks, or the
provision of greater control on social media 
which creates an illusion of safety and encourages
greater sharing.
Uncertainty, contextdependence, and malleability are closely connected. Contextdependence
is amplified by uncertainty. Because people are
often “at sea” when it comes to the conse
quences of, and their feelings about, privacy,
they cast around for cues to guide their be
havior. Privacy  and behaviors are,
in turn, malleable and subject to influence in
large part because they are contextdependent
and because those with an interest in informa
tion divulgence are able to manipulate context to
their advantage.
Uncertainty
Individuals manage the boundaries between
their private and public spheres in numerous
ways: via separateness, reserve, or anonymity
; by protecting personal information; but also
through deception and dissimulation . People
establish such boundaries for many reasons, in
cluding the need for intimacy and psychological
respite and the desire for protection from social
influence and control . Sometimes, these motivations are so visceral and primal that privacy
seeking behavior emerges swiftly and naturally. This
is often the case when physical privacy is intruded 
such as when a stranger encroaches in one’s per
sonal space (13–15) or demonstratively eavesdrops
on a conversation. However, at other times (often
including when informational privacy is at stake)
people experience considerable uncertainty about
whether, and to what degree, they should be con
cerned about privacy.
A first and most obvious source of privacy
uncertainty arises from incomplete and asym
metric information. Advancements in infor
mation technology have made the collection
and usage of personal data often invisible. As
a result, individuals rarely have clear knowl
edge of what information other people, firms,
and governments have about them or how that
information is used and with what consequences.
To the extent that people lack such informa
tion, or are aware of their ignorance, they are
likely to be uncertain about how much infor
mation to share.
Two factors exacerbate the difficulty of ascer
taining the potential consequences of privacy be
havior. First, whereas some privacy harms are
tangible, such as the financial costs associated
with identity theft, many others, such as having
strangers become aware of one’s life history, are
intangible. Second, privacy is rarely an unalloyed
good; it typically involves tradeoffs. When the search
engine only provided links to the merchants’ sites
and a comparison of the products’ prices from the
different sellers, a majority of participants did not
pay any attention to the merchants’ privacy poli
cies; they purchased from those offering the lowest
price. However, when the search engine also pro
vided participants with salient, easily accessible
information about the differences in privacy pro
tection afforded by the various merchants, a
majority of participants paid a roughly 5% pre
mium to buy products from (and share their
credit card information with) more privacy
protecting merchants.
A second source of privacy uncertainty relates
to p. Even when aware of the conse
quences of privacy decisions, people are still
likely to be uncertain about their own privacy
. Research on preference uncertainty
 shows that individuals often have little sense
of how much they like goods, services, or other
people. Privacy does not seem to be an exception.
This can be illustrated by research in which peo
ple were asked sensitive and potentially incrimi
nating questions either pointblank, or followed
by credible assurances of confidentiality . Al
though logically such assurances should lead to
greater divulgence, they often had the opposite
effect because they elevated respondents’ privacy
concerns, which without assurances would have
remained dormant.
The remarkable uncertainty of privacy prefer
ences comes into play in efforts to measure indi
vidual and group differences in preference for
privacy . For example, Westin  famously
used broad (that is, not contextually specific) pri
vacy questions in surveys to cluster individuals
into privacy segments: privacy fundamentalists,
pragmatists, andunconcerned. Whenaskeddirect
ly, many people fall in the first segment: They
profess to care a lot about privacy and express
particular concern over losing control of their
personal information or others gaining unau
thorized access to it (22, 23). However, doubts
about the power of attitudinal scales to predict
actual privacy behavior arose early in the liter
ature . This discrepancy between attitudes
and behaviors has become known as the “privacy
paradox.”
In one early study illustrating the paradox,
participants were first classified into categories
of privacy concern inspired by Westin’s cate
gorization based on their responses to a survey
dealing with attitudes toward sharing data
. Next, they were presented with products
to purchase at a discount with the assistance of
an anthropomorphic shopping agent. Few,
regardless of the group they were categorized
in, exhibited much reluctance to answering the
increasingly sensitive questions the agent plied
them with.
Why do people who claim to care about pri
vacy often show little concern about it in their
daily behavior? One possibility is that the para
dox is illusory that privacy attitudes, which are
defined broadly, and intentions and behaviors,
which are defined narrowly, should not be ex
pected to be closely related (26, 27). Thus, one
might care deeply about privacy in general but,
depending on the costs and benefits prevailing
in a specific situation, seek or not seek privacy
protection  .
This explanation for the privacy paradox, how
ever, is not entirely satisfactory for two reasons.
The first is that it fails to account for situations in
which attitudebehavior dichotomies arise under
high correspondence between expressed concerns
and behavioral actions. For example, one study
compared attitudinal survey answers to actual
social media behavior . Even within the sub
set of participants who expressed the highest
degree of concern over strangers being able to
easily find out their sexual orientation, political
views, and partners’ names, 48% did in fact pub
licly reveal their sexual orientation online, 47%
revealed their political orientation, and 21% re
vealed their current partner’s name. The second
reason is that privacy decisionmaking is only in
part the result of a rational “calculus” of costs
and benefits (16, 28); it is also affected by mis
perceptions of those costs and benefits, as well
as social norms, emotions, and heuristics. Any of
these factors may affect behavior differently from
how they affect attitudes. For instance, present
bias can cause even the privacyconscious to
engage in risky revelations of information, if
the immediate gratification from disclosure trumps
the delayed, and hence discounted, future con
sequences .
Preference uncertainty is evident not only in
studies that compare stated attitudes with behav
iors, but also in those that estimate monetary
valuations of privacy. “Explicit” investigations
ask people to make direct tradeoffs, typically
between privacy of data and money. For instance,
in a study conducted both in Singapore and the
United States, students made a series of hypo
thetical choices about sharing information with
websites that differed in protection of personal
information and prices for accessing services .
Using conjoint analysis, the authors concluded
that subjects valued protection against errors, im
proper access, and secondary use of personal
information between $30.49 and $44.62. Similar
to direct questions about attitudes and inten
tions, such explicit investigations of privacy
valuation spotlight privacy as an issue that re
spondents should take account of and, as a re
sult, increase the weight they place on privacy in
their responses.
Implicit investigations, in contrast, infer valu
ations of privacy from daytoday decisions in
which privacy is only one of many considerations
and is typically not highlighted. Individuals en
gage in privacyrelated transactions all the time,
even when the privacy tradeoffs may be in
tangible or when the exchange of personal data
may not be a visible or primary component of a
transaction. For instance, completing a query on
a search engine is akin to selling personal data
(one’s p and contextual interests) to the
engine in exchange for a service (search results).
“Revealed preference” economic arguments would
then conclude that because technologies for infor
mation sharing have been enormously successful,
whereas technologies for information protection
have not, individuals hold overall low valuations
of privacy. However, that is not always the case:
Although individuals at times give up personal
data for small benefits or discounts, at other times
they voluntarily incur substantial costs to protect
their privacy. Context, as further discussed in the
next section, matters.
In fact, attempts to pinpoint exact valuations
that people assign to privacy may be misguided,
as suggested by research calling into question the
stability, and hence validity, of privacy estimates.
In one field experiment inspired by the literature
on endowment effects , shoppers at a mall
were offered gift cards for participating in a non
sensitive survey. The cards could be used online or
in stores, just like debit cards. Participants were
given either a $10 “anonymous” gift card (trans
actions done with that card would not be traceable
to the subject) or a $12 trackable card (tran
sactions done with that card would be linked to
the name of the subject). Initially, half of the
participants were given one type of card, and half
the other. Then, they were all offered the op
portunity to switch. Some shoppers, for example,
were given the anonymous $10 card and were
asked whether they would accept $2 to “allow my
name to be linked to transactions done with the
card”; other subjects were asked whether they
would accept a card with $2 less value to “prevent
my name from being linked to transactions done
with the card.” Of the subjects who originally held
the less valuable but anonymous card, five times
as many (52.1%) chose it and kept it over the
other card than did those who originally held the
more valuable card (9.7%). This suggests that
people value privacy more when they have it
than when they do not.
The consistency of p for privacy is
also complicated by the existence of a powerful
countervailing motivation: the desire to be pub
lic, share, and disclose. Humans are social animals,
and information sharing is a central feature of
human connection. Social penetration theory 
suggests that progressively increasing levels of self
disclosure are an essential feature of the natural
and desirable evolution of interpersonal relation
ships from superficial to intimate. Such a progres
sion is only possible when people begin social
interactions with a baseline level of privacy. Para
doxically, therefore, privacy provides an essential
foundation for intimate disclosure. Similar to pri
vacy, selfdisclosure confers numerous objective
and subjective benefits, including psychological

 
and physical health (34, 35). The desire for inter
action, socialization, disclosure, and recognition
or fame (and, conversely, the fear of anonymous
unimportance) are human motives no less funda
mental than the need for privacy. The electronic
media of the current age provide unprecedented
opportunities for acting on them. Through so
cial media, disclosures can build social capital,
increase selfesteem , and fulfill ego needs
. In a series of functional magnetic reso
nance imaging experiments, selfdisclosure was
even found to engage neural mechanisms as
sociated with reward; people highly value the
ability to share thoughts and feelings with others.
Indeed, subjects in one of the experiments were
willing to forgo money in order to disclose about
themselves .
Contextdependence
Much evidence suggests that privacy is a uni
versal human need (Box 1) . However, when
people are uncertain about their p they
often search for cues in their environment to
provide guidance. And because cues are a func
tion of context, behavior is as well. Applied to
privacy, contextdependence means that individ
uals can, depending on the situation, exhibit any
thing ranging from extreme concern to apathy
about privacy. Adopting the terminology of Westin,
we are all privacy pragmatists, privacy funda
mentalists, or privacy unconcerned, depending
on time and place .
The way we construe and negotiate public
and private spheres is contextdependent because
the boundaries between the two are murky :
The rules people follow for managing privacy
vary by situation, are learned over time, and are
based on cultural, motivational, and purely situational criteria. For instance, usually we may be
more comfortable sharing secrets with friends,
but at times we may reveal surprisingly personal
information to a stranger on a plane . The
theory of contextual “integrity” posits that social
expectations affect our beliefs regarding what is
private and what is public, and that such expectations vary with specificcontexts . Thus, seeking
privacy in public is not a contradiction; individuals
can manage privacy even while sharing informa
tion, and even on social media . For instance,
a longitudinal study of actual disclosure behavior
of online social network users highlighted that
over time, many users increased the amount of per
sonal information revealed to their friends (those
connected to them on the network) while simul
taneously decreasing the amounts revealed to
strangers (those unconnected to them) (Fig. 1) .
The cues that people use to judge the importance of privacy sometimes result in sensible be
havior. For instance, the presence of government
regulation has been shown to reduce consumer
concern and increase trust; it is a cue that peopleuse to infer the existence of some degree of privacy protection . In other situations, however,cues can be unrelated, or even negatively related,
to normative bases of decisionmaking. For example, in one online experiment  individuals were
more likely to reveal personal and even incrimi
nating information on a website with an un
professional and casual design with the banner
“How Bad R U” than on a site with a formal
interface even though the site with the formal
interface was judged by other respondents to be
much safer (Fig. 2). Yet in other situations, it is
the physical environment that influences privacy
concern and associated behavior , sometimes
even unconsciously. For instance, all else being
equal, intimacy of selfdisclosure is higher in
warm, comfortable rooms, with soft lighting, than
in cold rooms with bare cement and overhead
fluorescent lighting .
Some of the cues that influence perceptions
of privacy are one’s culture and the behavior of
other people, either through the mechanism of
descriptive norms (imitation) or via reciprocity
. Observing other people reveal information
increases the likelihood that one will reveal it
oneself . In one study, surveytakers were asked
a series of sensitive personal questions regarding
their engagement in illegal or ethically question
able behaviors. After answering each question,
participants were provided with information, ma
nipulated unbeknownst to them, about the per
centage of other participants who in the same
survey had admitted to having engaged in a given
behavior. Being provided with information that
suggested that a majority of survey takers had
admitted a certainquestionable behavior increased
participants’ willingness to disclose their engage
ment in other, also sensitive, behaviors. Other
studies have found that the tendency to recip
rocate information disclosure is so ingrained that
people will reveal more information even to a
computer agent that provides information about
itself . Findings such as this may help to
explain the escalating amounts of selfdisclosure
we witness online: If others are doing it, people
seem to reason unconsciously, doing so oneself
must be desirable or safe.
Other people’s behavior affects privacy con
cerns in other ways, too. Sharing personal infor
mation with others makes them “coowners” of
that information  and, as such, responsible
for its protection. Mismanagement of shared
information by one or more coowners causes
“turbulence” of the privacy boundaries and, con
sequently, negative reactions, including anger or
mistrust. In a study of undergraduate Facebook
users , for instance, turbulence of privacy
boundaries, as a result of having one’s profile
exposed to unintended audiences, dramatically
increased the odds that a user would restrict pro
file visibility to friendsonly.
Likewise, privacy concerns are often a function
of past experiences. When something in an en
vironment changes, such as the introduction of a
camera or other monitoring devices, privacy con
cern is likely to be activated. For instance, surveil
lance can produce discomfort  and negatively
affect worker productivity .
Privacy behavior is
affected both by
endogenous motiva
tions (for instance,
subjective preferen
ces) and exogenous
factors (for instance,
changes in user inter
faces). In an experiment conducted in
Helsinki , the installation of sensing and mon
itoring technology in households led family mem
bers initially to change their behavior, particularly
in relation to conversations, nudity, and sex. And
yet, if they accidentally performed an activity, such
as walking naked into the kitchen in front of the
sensors, it seemed to have the effect of “breaking
the ice”; participants then showed less concern
about repeating the behavior. More generally, par
ticipants became inured to the presence of the
technology over time.
The contextdependence of privacy concern has
major implications for the risks associated with
modern information and communication technol
ogy . With online interactions, we no longer
have a clear sense of the spatial boundaries of our
listeners. Who is reading our blog post? Who is
looking at our photos online? Adding complexity
to privacy decisionmaking, boundaries between
public and private become even less defined in the
online world  where we become social media
friends with our coworkers and post pictures to
an indistinct flock of followers. With different so
cial groups mixing on the Internet, separating
online and offline identities and meeting our and
others’ expectations regarding privacy becomes
more difficult and consequential .
Malleability and influence
Whereas individuals are often unaware of the di
verse factors that determine their concern about
privacy in a particular situation, entities whose
prosperity depends on information revelation by
others are much more sophisticated. With the
emergence of the information age, growing insti
tutional and economic interests have developed
around disclosure of personal information, from
online social networks to behavioral advertising.
It is not surprising, therefore, that some entities
have an interest in, and have developed expertise
in, exploiting behavioral and psychological proces
ses to promote disclosure . Such efforts play on
the malleability of privacy p, a term we
use to refer to the observation that various, some
times subtle, factors can be used to activate or
suppress privacy concerns, which in turn affect
behavior.
Default settings are an important tool used by
different entities to affect information disclo
sure. A large body of research has shown that
default settings matter for decisions as important
as organ donation and retirement saving .
Sticking to default settings is convenient, and
people often interpret default settings as implicit
recommendations . Thus, it is not surprising
that default settings for one’s profile’s visibility on
social networks , or the existence of optin or
optout privacy policies on websites , affect
individuals’ privacy behavior (Fig. 3).
In addition to default settings, websites can
also use design features that frustrate or even con
fuse users into disclosing personal information
, a practice that has been referred to as “ma
licious interface design” . Another obvious
strategy that commercial entities can use to avoid
raising privacy concerns is notto “ring alarm bells”
when it comes to data collection. When companies
do ring them for example, by using overly fine
tuned personalized advertisements consumers
are alerted  and can respond with negative
“reactance” .
Various socalled “antecedents”  affect pri
vacy concerns and can be used to influence pri
vacy behavior. For instance, trust in the entity
receiving one’s personal data soothes concerns.
Moreover, because some interventions that are in
tended to protect privacy can establish trust, con
cerns can be muted by the very interventions
intended to protect privacy. Perversely, 62% of
respondents to a survey believed (incorrectly) that
the existence of a privacy policy implied that a site
could not share their personal information with
out permission , which suggests that simply
posting a policy that consumers do not read may
lead to misplaced feelings of being protected.
Control is another feature that can inculcate
trust and produce paradoxical effects. Perhaps be
cause of its lack of controversiality, control has
512
30 JANUARY 2015 • VOL 347 ISSUE 6221
sciencemag.org SCIENCE
Box 1. Privacy: A modern invention?
Is privacy a modern, bourgeois, and distinctly Western invention? Or are privacy needs a
universal feature of human societies? Although access to privacy is certainly affected by
socioeconomic factors  , and
privacy norms greatly differ across cultures (65, 85), the need for privacy seems to be a
universal human trait. Scholars have uncovered evidence of privacyseeking behaviors across
peoples and cultures separated by time and space: from ancient Rome and Greece (39, 88) to
preindustrialized Javanese, Balinese, and Tuareg societies (89, 90). Privacy, as Altman 
noted, appears to be simultaneously culturally specific and culturally universal. Cues of a
common human quest for privacy are also found in the texts of ancient religions: The Quran
(49:12) instructs against spying on one another ; the Talmud (Bava Batra 60a) advises
homebuilders to position windows so that they do not directly face those of one’s neighbors
; the Bible (Genesis, 3:7) relates how Adam and Eve discovered their nakedness after
eating the fruit of knowledge and covered themselves in shame from the prying eyes of God
 . Implicit in
this heterogeneous selection of historical examples is the observation that there exist
multiple notions of privacy. Although contemporary attention focuses on informational
privacy, privacy has been also construed as territorial and physical, and linked to concepts as
diverse as surveillance, exposure, intrusion, insecurity, appropriation, as well as secrecy,
protection, anonymity, dignity, or even freedom .
Fig. 2.The impact of cues on
disclosure behavior. A measure
of privacy behavior often used in
empirical studies is a subject’s
willigness to answer personal,
sometimes sensitive questions 
for instance, by admitting or
denying having engaged in
questionable behaviors. In an
online experiment , individ
uals were asked a series of
intrusive questions about their
behaviors, such as “Have you
ever tried to peek at someone
else’s email without them
knowing?” Across conditions,
the interface of the question
naire was manipulated to look
more or less professional. The
y axis captures the mean affir
mative admission rates (AARs)
to questions that were rated as
intrusive (the proportion of
questions answered affirma
tively) normed, question by ques
tion, on the overall average AAR for the question. Subjects revealed more personal and even incriminating
information on the website with a more casual design, even though the site with the formal interface was
judged by other respondents to be much safer.The study illustrates how cues can influence privacy behavior
in a fashion that is unrelated, or even negatively related, to normative bases of decisionmaking.
THE END OF PRIVACY
 
been one of the capstones of the focus of both
industry and policymakers in attempts to balance
privacy needs against the value of sharing. Control
over personal information is often perceived as a
critical feature of privacy protection . In principle, it does provide users with the means to
manage access to their personal information. Re
search, however, shows that control can reduce
privacy concern , which in turn can have un
intended effects. For instance, one study found
that participants who were provided with greater
explicit control over whether and how much of
their personal information researchers could
publish ended up sharing more sensitive informa
tion with a broader audience the opposite of the
ostensible purpose of providing such control .
Similar to the normative perspective on control,
increasing the transparency of firms’ data practices would seem to be desirable. However, trans
parency mechanisms can be easily rendered
ineffective. Research has highlighted not only that
an overwhelming majority of Internet users do
not read privacy policies , but also that few
users would benefit from doing so; nearly half of a
sample of online privacy policies were found to be
written in language beyond the grasp of most
Internet users . Indeed, and somewhat amus
ingly, it has been estimated that the aggregate
opportunity cost if U.S. consumers actually read
the privacy policies of the sites they visit would
be $781 billion/year .
Although uncertainty and contextdependence
lead naturally to malleability and manipulation,
not all malleability is necessarily sinister. Consider monitoring. Although monitoring can cause
discomfort and reduce productivity, the feeling of
being observed and accountable can induce peo
ple to engage in prosocial behaviors or (for better
or for worse) adhere to social norms . Prosocial
behavior can be heightened by monitoring cues as
simple as three dots in a stylized face configura
tion . By the same token, the depersonalization
induced by computermediated interaction ,
either in the form of lack of identifiability or of
visual anonymity , can have beneficial effects,
such as increasing truthful responses to sensitive
surveys . Whether elevating or suppressing
privacy concerns is socially beneficial critically depends, yet again, on context [a metaanalysis of the
impact of deidentification on behavior is provided
in . For example, perceptions of anonymity
can alternatively lead to dishonest or prosocial
behavior. Illusory anonymity induced by darkness
caused participants in an experiment  to cheat
in order to gain more money. This can be inter
preted as a form of disinhibition effect , by
which perceived anonymity licenses people to act
in ways that they would otherwise not even con
sider. In other circumstances, though, anonymity
leads to prosocial behavior for instance, higher
willingness to share money in a dictator game,
when coupled with priming of religiosity .
Conclusions
Norms and behaviors regarding private and pub
lic realms greatly differ across cultures . Amer
icans, for example, are reputed to be more open
about sexual matters than are the Chinese, whereas
the latter are more open about financial matters
(such as income, cost of home, and possessions).
And even within cultures, people differ substan
tially in how much they care about privacy and
what information they treat as private. And as we
have sought to highlight in this Review, privacy
concerns can vary dramatically for the same in
dividual, and for societies, over time.
If privacy behaviors are culture and context
dependent, however, the dilemma of what to share
and what to keep private is universal across so
cieties and over human history. The task of nav
igating those boundaries, and the consequences
of mismanaging them, have grown increasingly
complex and fateful in the information age, to
the point that our natural instincts seem not
nearly adequate.
In this Review,we usedthree themesto organize
and draw connections between the social and be
havioral science literatures on privacy and behav
ior. We end the Review with a brief discussion of
the reviewed literature’s relevance to privacy policy.
Uncertainty and contextdependence imply that
people cannot always be counted on to navigate
the complex tradeoffs involving privacy in a self
interested fashion. People are often unaware of
the information they are sharing, unaware of how
it can be used, and even in the rare situations
when they have full knowledge of the conse
quences of sharing, uncertain about their own
Malleability, in turn, implies that peo
ple are easily influenced in what and how much
they disclose. Moreover, what they share can be
used to influence their emotions, thoughts, and
behaviors in many aspects of their lives, as in
dividuals, consumers, and citizens. Although such
influence is not always or necessarily malevolent
or dangerous.
